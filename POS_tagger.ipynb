{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "#import nltk\n",
    "from nltk.tag import StanfordNERTagger\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "#os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:/Users/axmarr/Documents/Varios/maestria/NLP/NLP-master/'\n",
    "\n",
    "#path = 'C:/Users/Kikes/Documents/GitHub/NLP/df_comms.csv'\n",
    "\n",
    "comentarios = pd.read_csv(path+'df_comms.csv', encoding='utf-8', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = comentarios.copy().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comm_msg'].replace('', np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['emojis'].replace('', np.nan, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['solo_emoji'] = np.where(df.comm_msg.isnull()&df.emojis.notnull(),1,0)\n",
    "#comentarios[comentarios.solo_emoji == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropeo filas con comentarios y sin emojis\n",
    "df.dropna( subset = ['comm_msg', 'solo_emoji'], inplace = True, how = 'all' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axmarr\\Documents\\Python\\WinPython-64bit-3.6.1.0Qt5\\python-3.6.1.amd64\\lib\\site-packages\\nltk\\tag\\stanford.py:183: DeprecationWarning: \n",
      "The StanfordTokenizer will be deprecated in version 3.2.5.\n",
      "Please use \u001b[91mnltk.tag.corenlp.CoreNLPPOSTagger\u001b[0m or \u001b[91mnltk.tag.corenlp.CoreNLPNERTagger\u001b[0m instead.\n",
      "  super(StanfordNERTagger, self).__init__(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Desde acá: https://nlp.stanford.edu/software/CRF-NER.shtml#Download\n",
    "#Se baja: https://nlp.stanford.edu/software/stanford-ner-2017-06-09.zip\n",
    "#Se descomprime el .zip y a la carpeta que está adentro se le cambia el nombre de: stanford-ner-2017-06-09 a: stanford-ner \n",
    "\n",
    "#import os\n",
    "java_path = \"C:/Program Files/Java/jre1.8.0_131/bin/java.exe\"\n",
    "#java_path = 'C:/Program Files (x86)/Java/jre1.8.0_131/bin/java.exe'\n",
    "\n",
    "os.environ['JAVAHOME'] = java_path\n",
    "\n",
    "#os.getcwd()\n",
    "#Hay que cambiar el directorio y que apunte donde está la carpeta que descomprimimos\n",
    "os.chdir(\"C:/Users/axmarr/Documents/Varios/maestria/NLP/\")\n",
    "#os.chdir('C:/Users/Kikes/Documents/maestria/NLP/')\n",
    "\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "#from nltk.tag import StanfordNERTagger\n",
    "#from nltk.tokenize import word_tokenize\n",
    "\n",
    "st = StanfordNERTagger('stanford-ner/classifiers/spanish.ancora.distsim.s512.crf.ser.gz',\n",
    "\t\t\t\t\t   'stanford-ner/stanford-ner.jar',\n",
    "\t\t\t\t\t   encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraeNombres(comm):\n",
    "    comm_str = str(comm)#comm.to_json()\n",
    "    #comm_token = word_tokenize(comm_str)\n",
    "    comm_token = word_tokenize(comm_str)\n",
    "    #comm_token = word_tokenize(comm)\n",
    "    comm_class = st.tag(comm_token)\n",
    "    comm_list_per = [pers for pers in comm_class if pers[1] =='PERS']\n",
    "    comm_per = re.sub(r'[\\[\\]\\(\\)\\'\\,]', \"\", str([i[0] for i in comm_list_per]))\n",
    "    return comm_per"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ver como optimizar este punto, el cuello de botella esta en st.tag()\n",
    "#https://engineering.upside.com/a-beginners-guide-to-optimizing-pandas-code-for-speed-c09ef2c6a4d6\n",
    "\n",
    "#pd.options.mode.chained_assignment = None\n",
    "df['nombres'] = df['comm_msg'].apply(lambda x: extraeNombres(x))\n",
    "df['nombres'].replace( '', np.nan, inplace = True )\n",
    "#comentarios['nombres'] = comentarios['comm_msg'].apply(lambda x: extraeNombres(x))\n",
    "#pd.options.mode.chained_assignment = 'warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\axmarr\\Documents\\Python\\WinPython-64bit-3.6.1.0Qt5\\python-3.6.1.amd64\\lib\\site-packages\\ipykernel\\__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "n_comm = len(df)\n",
    "\n",
    "for c in range(n_comm):\n",
    "    ext_name = str(df.nombres[c])\n",
    "    ext_comm = str(df.comm_msg[c])\n",
    "    comm_no_name = ext_comm.replace(ext_name,\"\")\n",
    "    df.comm_msg[c] = comm_no_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comm_msg'].replace( '', np.nan, inplace = True )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['solo_nombre'] = np.where( df.comm_msg.isnull()&df.nombres.isnull()&df.emojis.notnull(), 1, 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tiene_nombre'] = np.where( df.nombres.notnull(), 1, 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tiene_emoji'] = np.where( df.emojis.notnull(), 1, 0 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['largo_comm'] = df['comm_msg'].apply(lambda x: len(x.replace(\" \",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['comm_msg'] = df['comm_msg'].apply(lambda x: re.sub(r'[!#$%&\\'()*+,-./:;<=>?@\\[\\]^_`{|}~¡]', \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://stackoverflow.com/questions/19130512/stopword-removal-with-nltk\n",
    "#from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('spanish'))\n",
    "sw2 = set(line.strip() for line in open('stop_words_acentos.txt'))\n",
    "stop2 = stop|sw2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#comm  = df['comm_msg'][1]\n",
    "\n",
    "def quitaStopWords(comm):\n",
    "\n",
    "    split_comm = comm.lower().split()\n",
    "    comm_no_stop = [i for i in split_comm if i not in stop2]\n",
    "    comm_str = ' '.join(comm_no_stop)\n",
    "    comm_str_no_short = ' '.join(word for word in comm_str.split() if len(word)>2)\n",
    "    return comm_str_no_short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['comm_msg_clean'] = df['comm_msg'].apply( lambda x: quitaStopWords( x ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['largo_comm_clean'] = df['comm_msg_clean'].apply(lambda x: len(x.replace(\" \",\"\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['ratio_largo_clean'] = df['largo_comm_clean']/df['largo_comm']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv( 'df_final.csv', encoding = 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[['comm_msg_clean', 'comm_msg', 'largo_comm', 'largo_comm_clean', 'ratio_largo_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nube de tags\n",
    "#https://www.kaggle.com/ngyptr/python-nltk-sentiment-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.chdir('C:/Users/Kikes/Documents/maestria/NLP/')\n",
    "#df_com = pd.read_csv('comentarios.csv', encoding='utf-8', index_col = 0)\n",
    "#df_com.head(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
